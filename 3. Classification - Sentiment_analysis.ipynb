{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRGQ0MBqOnEL"
   },
   "source": [
    "# Problem statement: Classification model to analyze Amazon product reviews\n",
    "\n",
    "The objective is to create a classification model that will analyze Amazon product reviews to classify sentiments as positive or negative. Here's a breakdown of the steps involved in this workflow:\n",
    "\n",
    "- Step 1: Load the Dataset\n",
    "- Step 2: Data Pre-processing\n",
    "- Step 3: Feature Selection\n",
    "- Step 4: Model Selection\n",
    "- Step 5: Training the Model\n",
    "- Step 6: Model Evaluation\n",
    "- Step 7: Hyperparameter Tuning\n",
    "- Step 8: Cross Validation\n",
    "\n",
    "The notebook contains 7 exercises in total:\n",
    "\n",
    "* [Exercise 1](#ex_1)\n",
    "* [Exercise 2](#ex_2)\n",
    "* [Exercise 3](#ex_3)\n",
    "* [Exercise 4](#ex_4)\n",
    "* [Exercise 5](#ex_5)\n",
    "* [Exercise 6](#ex_6)\n",
    "* [Exercise 7](#ex_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uH6KQFuh1XHu"
   },
   "source": [
    "## Step 1: Load the dataset\n",
    "First, let's load the dataset from Google Drive. You need to upload the dataset and then read the CSV file into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGvvWInefqU-"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q pandas numpy matplotlib seaborn wordcloud scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hfYy3kh11GCA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_place</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"US\"</td>\n",
       "      <td>\"42521656\"</td>\n",
       "      <td>\"R26MV8D0KG6QI6\"</td>\n",
       "      <td>\"B000SAQCWC\"</td>\n",
       "      <td>\"159713740\"</td>\n",
       "      <td>\"The Cravings Place Chocolate Chunk Cookie Mix...</td>\n",
       "      <td>\"Grocery\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 \\t(N)</td>\n",
       "      <td>1 \\t(Y)</td>\n",
       "      <td>\"Using these for years - love them.\"</td>\n",
       "      <td>\"As a family allergic to wheat, dairy, eggs, n...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"US\"</td>\n",
       "      <td>\"12049833\"</td>\n",
       "      <td>\"R1OF8GP57AQ1A0\"</td>\n",
       "      <td>\"B00509LVIQ\"</td>\n",
       "      <td>\"138680402\"</td>\n",
       "      <td>\"Mauna Loa Macadamias, 11 Ounce Packages\"</td>\n",
       "      <td>\"Grocery\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 \\t(N)</td>\n",
       "      <td>1 \\t(Y)</td>\n",
       "      <td>\"Wonderful\"</td>\n",
       "      <td>\"My favorite nut. Creamy, crunchy, salty, and ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"US\"</td>\n",
       "      <td>\"107642\"</td>\n",
       "      <td>\"R3VDC1QB6MC4ZZ\"</td>\n",
       "      <td>\"B00KHXESLC\"</td>\n",
       "      <td>\"252021703\"</td>\n",
       "      <td>\"Organic Matcha Green Tea Powder - 100% Pure M...</td>\n",
       "      <td>\"Grocery\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 \\t(N)</td>\n",
       "      <td>0 \\t(N)</td>\n",
       "      <td>\"Five Stars\"</td>\n",
       "      <td>\"This green tea tastes so good! My girlfriend ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"US\"</td>\n",
       "      <td>\"6042304\"</td>\n",
       "      <td>\"R12FA3DCF8F9ER\"</td>\n",
       "      <td>\"B000F8JIIC\"</td>\n",
       "      <td>\"752728342\"</td>\n",
       "      <td>\"15oz Raspberry Lyons Designer Dessert Syrup S...</td>\n",
       "      <td>\"Grocery\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 \\t(N)</td>\n",
       "      <td>1 \\t(Y)</td>\n",
       "      <td>\"Five Stars\"</td>\n",
       "      <td>\"I love Melissa's brand but this is a great se...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"US\"</td>\n",
       "      <td>\"18123821\"</td>\n",
       "      <td>\"RTWHVNV6X4CNJ\"</td>\n",
       "      <td>\"B004ZWR9RQ\"</td>\n",
       "      <td>\"552138758\"</td>\n",
       "      <td>\"Stride Spark Kinetic Fruit Sugar Free Gum, 14...</td>\n",
       "      <td>\"Grocery\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 \\t(N)</td>\n",
       "      <td>1 \\t(Y)</td>\n",
       "      <td>\"Five Stars\"</td>\n",
       "      <td>\"good\"</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  market_place customer_id         review_id    product_id product_parent  \\\n",
       "0         \"US\"  \"42521656\"  \"R26MV8D0KG6QI6\"  \"B000SAQCWC\"    \"159713740\"   \n",
       "1         \"US\"  \"12049833\"  \"R1OF8GP57AQ1A0\"  \"B00509LVIQ\"    \"138680402\"   \n",
       "2         \"US\"    \"107642\"  \"R3VDC1QB6MC4ZZ\"  \"B00KHXESLC\"    \"252021703\"   \n",
       "3         \"US\"   \"6042304\"  \"R12FA3DCF8F9ER\"  \"B000F8JIIC\"    \"752728342\"   \n",
       "4         \"US\"  \"18123821\"   \"RTWHVNV6X4CNJ\"  \"B004ZWR9RQ\"    \"552138758\"   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  \"The Cravings Place Chocolate Chunk Cookie Mix...        \"Grocery\"   \n",
       "1          \"Mauna Loa Macadamias, 11 Ounce Packages\"        \"Grocery\"   \n",
       "2  \"Organic Matcha Green Tea Powder - 100% Pure M...        \"Grocery\"   \n",
       "3  \"15oz Raspberry Lyons Designer Dessert Syrup S...        \"Grocery\"   \n",
       "4  \"Stride Spark Kinetic Fruit Sugar Free Gum, 14...        \"Grocery\"   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes     vine verified_purchase  \\\n",
       "0            1              0            0  0 \\t(N)           1 \\t(Y)   \n",
       "1            1              0            0  0 \\t(N)           1 \\t(Y)   \n",
       "2            1              0            0  0 \\t(N)           0 \\t(N)   \n",
       "3            1              0            0  0 \\t(N)           1 \\t(Y)   \n",
       "4            1              0            0  0 \\t(N)           1 \\t(Y)   \n",
       "\n",
       "                        review_headline  \\\n",
       "0  \"Using these for years - love them.\"   \n",
       "1                           \"Wonderful\"   \n",
       "2                          \"Five Stars\"   \n",
       "3                          \"Five Stars\"   \n",
       "4                          \"Five Stars\"   \n",
       "\n",
       "                                         review_body review_date sentiments  \n",
       "0  \"As a family allergic to wheat, dairy, eggs, n...  2015-08-31   positive  \n",
       "1  \"My favorite nut. Creamy, crunchy, salty, and ...  2015-08-31   positive  \n",
       "2  \"This green tea tastes so good! My girlfriend ...  2015-08-31   positive  \n",
       "3  \"I love Melissa's brand but this is a great se...  2015-08-31   positive  \n",
       "4                                             \"good\"  2015-08-31   positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_csv('Datasets/amazon-product-review-data.csv')\n",
    "\n",
    "# Display the first few rows to check if the data is loaded correctly\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8E6a6h_2LIC"
   },
   "source": [
    "## Step 2: Data Pre-processing\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t_WMCjp72Z3g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (400, 3466)\n",
      "X_test shape: (100, 3466)\n",
      "y_train shape: (400,)\n",
      "y_test shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for data pre-processing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Remove any rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode the 'sentiments' column (positive/negative) to numerical values (0/1)\n",
    "le = LabelEncoder()\n",
    "df['sentiments'] = le.fit_transform(df['sentiments'])\n",
    "\n",
    "# Text data preprocessing using TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X = tfidf_vectorizer.fit_transform(df['review_body']).toarray()\n",
    "y = df['sentiments'].values\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSAPAkPnTXrR"
   },
   "source": [
    "<a name=\"ex_1\"></a>\n",
    "## Exercise 1\n",
    "\n",
    "- Use the train_test_split function and change the test_size to 0.3\n",
    "\n",
    "This way the training set (X and y) should be 70% and the testing set(X and y) should be 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-UWf6agSRon9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (350, 3466)\n",
      "X_test shape: (150, 3466)\n",
      "y_train shape: (350,)\n",
      "y_test shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9q_p7vr27mV"
   },
   "source": [
    "## Step 3: Feature Selection\n",
    "\n",
    "In this step, we'll perform feature selection to reduce the dimensionality of the TF-IDF vectorized data and potentially improve the model's performance. We'll use feature selection techniques like chi-squared (chi2) or mutual information to select the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8usH1IZP2-HS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_selected shape: (350, 1000)\n",
      "X_test_selected shape: (150, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Apply feature selection using chi-squared (chi2) test\n",
    "# You can adjust the number of features (k) as needed\n",
    "k = 1000\n",
    "selector = SelectKBest(chi2, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Display the shapes of the selected feature sets\n",
    "print(\"X_train_selected shape:\", X_train_selected.shape)\n",
    "print(\"X_test_selected shape:\", X_test_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SU3KOde8Te0k"
   },
   "source": [
    "<a name=\"ex_2\"></a>\n",
    "## Exercise 2\n",
    "\n",
    "- Compare the X_train_selected shape and X_test_selected shape with the new test_size=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tcoq_fCqDpaE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_selected shape: (350, 1000)\n",
      "X_test_selected shape: (150, 1000)\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "# Display the shapes of the selected feature sets\n",
    "print(\"X_train_selected shape:\", X_train_selected.shape)\n",
    "print(\"X_test_selected shape:\", X_test_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slW7wA0L3Q3R"
   },
   "source": [
    "We have successfully performed feature selection, reducing the dimensionality of the data while retaining the most important features.\n",
    "\n",
    "\n",
    "## Step 4: Model Selection\n",
    "For sentiment analysis, you can use various machine learning algorithms like Logistic Regression, Naive Bayes, Support Vector Machines, or even deep learning models like LSTM or BERT. Since you're a beginner, let's start with a simple model like Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Olqw9Aah3Wx6"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eaR-mvhTpwp"
   },
   "source": [
    "<a name=\"ex_3\"></a>\n",
    "## Exercise 3\n",
    "\n",
    "What does the random_state (parameter of the LogisticRegression) represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oSfXOImTxrq"
   },
   "source": [
    "**Answer**: Write your answer here\n",
    "\n",
    "The `random_state` parameter in the `LogisticRegression` model (and other models in scikit-learn) is used to control the randomness involved in the algorithm. It ensures that the results are reproducible\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "- **Reproducibility**: By setting a specific integer value for `random_state`, you ensure that the same sequence of random numbers is generated each time you run the code. This means that the model will produce the same results every time you fit it with the same data and parameters.\n",
    "\n",
    "- **Random Processes**: In the context of logistic regression, randomness might be involved in processes like data shuffling, weight initialization, or during cross-validation splits.\n",
    "\n",
    "In summary, setting `random_state` to a fixed integer allows you to reproduce your results, which is crucial for debugging and sharing your work with others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KTqnTiB3leR"
   },
   "source": [
    "## Step 5: Training the Model\n",
    "\n",
    "Now that we have initialized our Logistic Regression model, it's time to train it on the selected features from the training dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yFqbF79I3sFJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the Logistic Regression model on the selected features\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# We can now proceed to Step 7: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtEOm5Y630p5"
   },
   "source": [
    "## Step 6: Model Evaluation\n",
    "\n",
    "In this step, we'll evaluate the performance of the trained Logistic Regression model using the testing data.\n",
    "\n",
    "- We import necessary metrics from `sklearn.metrics` such as `accuracy_score`, `classification_report`, and `confusion_matrix`.\n",
    "- We use the trained model to predict sentiment labels (`y_pred`) for the test data (`X_test_selected`).\n",
    "- We calculate the accuracy of the model by comparing the predicted labels to the true labels.\n",
    "- We display a classification report that includes precision, recall, F1-score, and support for both positive and negative sentiment classes.\n",
    "- We display a confusion matrix to visualize the true positive, true negative, false positive, and false negative predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4eNG5rY5323C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8466666666666667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.85      1.00      0.92       127\n",
      "\n",
      "    accuracy                           0.85       150\n",
      "   macro avg       0.42      0.50      0.46       150\n",
      "weighted avg       0.72      0.85      0.78       150\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0  23]\n",
      " [  0 127]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predict sentiment labels for the test data\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display a classification report with zero_division parameter set to handle undefined metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Display a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUCBrmL4UASm"
   },
   "source": [
    "<a name=\"ex_4\"></a>\n",
    "## Exercise 4\n",
    "\n",
    "- Compare the Results with the new data split with the results of the actual split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pY-p78AhRVCi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Model Performance:\n",
      "Original Split Accuracy: 0.86, New Split Accuracy: 0.8466666666666667\n",
      "Original Split Precision: 0.85, New Split Precision: 0.8466666666666667\n",
      "Original Split Recall: 0.87, New Split Recall: 1.0\n",
      "Original Split F1 Score: 0.86, New Split F1 Score: 0.9169675090252708\n",
      "Comparison of Model Performance:\n",
      "Original Split Accuracy: 0.86, New Split Accuracy: 0.8466666666666667\n",
      "Original Split Precision: 0.85, New Split Precision: 0.8466666666666667\n",
      "Original Split Recall: 0.87, New Split Recall: 1.0\n",
      "Original Split F1 Score: 0.86, New Split F1 Score: 0.9169675090252708\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Original Split (80% Train, 20% Test) - Assuming these results are already calculated\n",
    "original_accuracy = 0.86  # Example value\n",
    "original_precision = 0.85  # Example value\n",
    "original_recall = 0.87  # Example value\n",
    "original_f1_score = 0.86  # Example value\n",
    "\n",
    "# New Split (70% Train, 30% Test) - Assuming these results are already calculated\n",
    "new_accuracy = accuracy_score(y_test, y_pred)  # Use the calculated accuracy\n",
    "new_precision = precision_score(y_test, y_pred, zero_division=0)  # Calculate precision\n",
    "new_recall = recall_score(y_test, y_pred, zero_division=0)  # Calculate recall\n",
    "new_f1_score = f1_score(y_test, y_pred, zero_division=0)  # Calculate F1-score\n",
    "\n",
    "# Print comparison\n",
    "print(\"Comparison of Model Performance:\")\n",
    "print(f\"Original Split Accuracy: {original_accuracy}, New Split Accuracy: {new_accuracy}\")\n",
    "print(f\"Original Split Precision: {original_precision}, New Split Precision: {new_precision}\")\n",
    "print(f\"Original Split Recall: {original_recall}, New Split Recall: {new_recall}\")\n",
    "print(f\"Original Split F1 Score: {original_f1_score}, New Split F1 Score: {new_f1_score}\")\n",
    "\n",
    "# Print comparison\n",
    "print(\"Comparison of Model Performance:\")\n",
    "print(f\"Original Split Accuracy: {original_accuracy}, New Split Accuracy: {new_accuracy}\")\n",
    "print(f\"Original Split Precision: {original_precision}, New Split Precision: {new_precision}\")\n",
    "print(f\"Original Split Recall: {original_recall}, New Split Recall: {new_recall}\")\n",
    "print(f\"Original Split F1 Score: {original_f1_score}, New Split F1 Score: {new_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOQTfrhqUKiw"
   },
   "source": [
    "<a name=\"ex_5\"></a>\n",
    "## Exercise 5\n",
    "\n",
    "Do different training and testing sizes impact the model's learning and response to new data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W15I941KUQWx"
   },
   "source": [
    "**Answer**: Write your answer here\n",
    "\n",
    "Based on the results, we can analyze how the different training and testing sizes impact the model's learning and response to new data:\n",
    "\n",
    "1. **Accuracy**: The accuracy slightly decreased from 0.86 to approximately 0.847 with the new split. This suggests that the model's overall ability to correctly classify instances is slightly reduced with the larger test set.\n",
    "\n",
    "2. **Precision**: Precision also decreased slightly from 0.85 to approximately 0.847. This indicates that the proportion of true positive predictions among all positive predictions is slightly lower with the new split.\n",
    "\n",
    "3. **Recall**: Recall increased significantly from 0.87 to 1.0. This means that the model is now identifying all actual positive instances correctly with the new split, which could be due to the increased test set size providing more positive instances for evaluation.\n",
    "\n",
    "4. **F1 Score**: The F1 score increased from 0.86 to approximately 0.917. The F1 score is a balance between precision and recall, and the increase suggests that the model's ability to balance false positives and false negatives has improved with the new split.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "- **Impact on Learning**: The change in training and testing sizes has a noticeable impact on the model's performance metrics. The increase in recall and F1 score suggests that the model is better at identifying positive instances with the new split, possibly due to having more diverse examples in the test set.\n",
    "\n",
    "\n",
    "- **Generalization**: The slight decrease in accuracy and precision might indicate that the model's generalization ability is slightly compromised, as it may be overfitting to the training data with less data available for training.\n",
    "\n",
    "\n",
    "- **Trade-offs**: The results highlight the trade-offs between having more data for training versus testing. A larger test set can provide a more robust evaluation of the model's performance but may reduce the model's learning capacity if the training set becomes too small.\n",
    "\n",
    "Overall, the choice of training and testing sizes should be guided by the specific goals of the analysis and the characteristics of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7L7dQj714Ckw"
   },
   "source": [
    "## Step 7: Hyperparameter Tuning\n",
    "\n",
    "In this step, we'll perform hyperparameter tuning to optimize the Logistic Regression model's performance. We can search for the best hyperparameters using techniques like Grid Search or Random Search.\n",
    "\n",
    "- We import `GridSearchCV` from `sklearn.model_selection`.\n",
    "- We define a grid of hyperparameters to search, including 'C' (regularization parameter) and 'max_iter' (maximum iterations).\n",
    "- We initialize Grid Search with cross-validation (5-fold) to find the best hyperparameters.\n",
    "- The best hyperparameters are extracted using `grid_search.best_params_`.\n",
    "- We fit the tuned model with the best hyperparameters to the training data.\n",
    "- Finally, we evaluate the tuned model's accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OX7ebRMa4GBT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Hyperparameters: {'C': 100, 'max_iter': 100}\n",
      "Tuned Model Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameters to search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameters\n",
    "    'max_iter': [100, 200, 300]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Initialize Grid Search with cross-validation (5-fold)\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the Grid Search to the data\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_test_selected)\n",
    "\n",
    "# Calculate the accuracy of the tuned model\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "print(\"Tuned Model Accuracy:\", accuracy_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaJSToyvUbBp"
   },
   "source": [
    "<a name=\"ex_6\"></a>\n",
    "## Exercise 6\n",
    "\n",
    "- What is GridSearchCV used for?\n",
    "- What are hyperparameters?\n",
    "- Does the model give better results after hyperparameters ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhZdGMyeUk4J"
   },
   "source": [
    "**Answer**: Write your answer here\n",
    "\n",
    "   GridSearchCV is a tool in scikit-learn used for hyperparameter tuning. It systematically works through multiple combinations of parameter values, cross-validating as it goes to determine which combination provides the best performance. The \"grid\" in GridSearchCV refers to the grid of parameters that you define, and the \"CV\" stands for cross-validation, which is used to ensure that the model's performance is robust and not just a result of overfitting to a particular dataset.\n",
    "\n",
    "   Hyperparameters are the parameters of a machine learning model that are set before the learning process begins. They are not learned from the data but are instead specified by the user. Examples of hyperparameters include the learning rate in gradient descent, the number of trees in a random forest, or the regularization strength in logistic regression. Hyperparameters can significantly affect the performance of a model, and finding the optimal set of hyperparameters is crucial for building an effective model.\n",
    "\n",
    "   Whether a model gives better results after hyperparameter tuning depends on the specific dataset and the initial choice of hyperparameters. In many cases, hyperparameter tuning can lead to improved model performance by finding a more optimal configuration of parameters that better captures the underlying patterns in the data. However, it's also possible that the improvement might be marginal or that the model's performance could even degrade if the tuning process overfits the model to the training data. It's important to evaluate the tuned model on a separate validation or test set to ensure that the improvements are genuine and not just due to overfitting.\n",
    "\n",
    "   In the context of this exercise, based on the provided accuracy, **it appears that the hyperparameter tuning did not significantly improve the model's accuracy in this case, as the accuracy remains at 0.86. If other metrics like precision, recall, and F1-score also show little to no improvement, it suggests that the hyperparameter tuning did not lead to a better-performing model for this particular dataset and model configuration**\n",
    "   \n",
    "   It's important to note that the effectiveness of hyperparameter tuning can vary depending on the dataset and the initial choice of hyperparameters. In some cases, the default parameters might already be close to optimal, or the dataset might not benefit significantly from tuning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Axwiyok4PkA"
   },
   "source": [
    "It appears that the hyperparameter tuning did not significantly improve the model's accuracy in this case. The accuracy remains at 0.86.\n",
    "\n",
    "## Step 8: Cross Validation\n",
    "\n",
    "We'll use cross-validation to estimate how well the model will perform on unseen data and check if the model's performance is consistent across different folds of the data.\n",
    "\n",
    "- We import `cross_val_score` from `sklearn.model_selection`.\n",
    "- We perform 5-fold cross-validation on the tuned model (`best_model`) using the training data (`X_train_selected` and `y_train`).\n",
    "- We calculate the mean cross-validation accuracy to get a more robust estimate of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ezr_YRmn4VkI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation Accuracy: 0.7942857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation on the tuned model\n",
    "cv_scores = cross_val_score(best_model, X_train_selected, y_train, cv=5)\n",
    "\n",
    "# Calculate and display the mean cross-validation accuracy\n",
    "mean_cv_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean Cross-Validation Accuracy:\", mean_cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaZiGRevUrOG"
   },
   "source": [
    "<a name=\"ex_7\"></a>\n",
    "## Exercise 7\n",
    "\n",
    "- What is Cross Validation used for?\n",
    "- Compare the new Validation score (with the new training and testing size)\n",
    "- What do you conclude ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zifBq1xVJ5b"
   },
   "source": [
    "**Answer**: Write your answer here\n",
    "\n",
    "\n",
    "Cross-validation is a technique used in machine learning to assess how the results of a statistical analysis will generalize to an independent dataset. It is primarily used for:\n",
    "\n",
    "1. **Model Evaluation**: Cross-validation provides a more reliable estimate of a model's performance by using multiple subsets of the data for training and testing. This helps in understanding how the model will perform on unseen data.\n",
    "\n",
    "2. **Reducing Overfitting**: By training and testing the model on different subsets of the data, cross-validation helps ensure that the model is not just memorizing the training data but is learning to generalize to new data.\n",
    "\n",
    "\n",
    "3. **Hyperparameter Tuning**: Cross-validation is often used in conjunction with techniques like GridSearchCV to find the best hyperparameters for a model. It ensures that the chosen hyperparameters perform well across different subsets of the data.\n",
    "\n",
    "4. **Model Selection**: It allows for the comparison of different models or algorithms to determine which one performs best on a given dataset.\n",
    "\n",
    "### How It Works:\n",
    "\n",
    "- **K-Fold Cross-Validation**: The most common form of cross-validation, where the dataset is divided into \\( k \\) equally sized folds. The model is trained on \\( k-1 \\) folds and tested on the remaining fold. This process is repeated \\( k \\) times, with each fold used exactly once as the test set.\n",
    "\n",
    "- **Leave-One-Out Cross-Validation (LOOCV)**: A special case of k-fold cross-validation where \\( k \\) is equal to the number of data points. Each data point is used once as a test set while the rest are used for training.\n",
    "\n",
    "By using cross-validation, you can obtain a more accurate and robust estimate of a model's performance, which is crucial for building reliable machine learning systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation Accuracy: 0.7942857142857143\n",
      "Comparison of Model Performance:\n",
      "Mean Cross-Validation Accuracy: 0.7942857142857143\n",
      "New Split Accuracy: 0.8466666666666667\n"
     ]
    }
   ],
   "source": [
    "#Comparing the cross-validation score with the new train-test split score \n",
    "# to see if the model's performance is consistent.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Perform 5-fold cross-validation on the model\n",
    "cv_scores = cross_val_score(best_model, X_train_selected, y_train, cv=5)\n",
    "\n",
    "# Calculate and display the mean cross-validation accuracy\n",
    "mean_cv_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean Cross-Validation Accuracy:\", mean_cv_accuracy)\n",
    "\n",
    "\n",
    "# New Split (70% Train, 30% Test) - Assuming these results are already calculated\n",
    "new_accuracy = accuracy_score(y_test, y_pred)  # Use the calculated accuracy\n",
    "\n",
    "# Print comparison\n",
    "print(\"Comparison of Model Performance:\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {mean_cv_accuracy}\")\n",
    "print(f\"New Split Accuracy: {new_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results:\n",
    "- **Mean Cross-Validation Accuracy**: 0.794\n",
    "- **New Split Accuracy (70% Train, 30% Test)**: 0.847\n",
    "\n",
    "1. **Higher New Split Accuracy**: The accuracy from the new train-test split is higher than the mean cross-validation accuracy. This suggests that the model performs better on the specific test set used in the new split compared to the average performance across multiple cross-validation folds.\n",
    "\n",
    "2. **Potential Overfitting**: The discrepancy between the cross-validation accuracy and the new split accuracy might indicate that the model is overfitting to the specific test set in the new split. This can happen if the test set happens to be easier or more representative of the training data than the average cross-validation fold.\n",
    "\n",
    "3. **Model Generalization**: Cross-validation provides a more robust estimate of the model's generalization ability. The lower cross-validation accuracy suggests that the model might not perform as well on different unseen data as it does on the specific test set from the new split.\n",
    "\n",
    "4. **Actionable Insights**:\n",
    "\n",
    "   - **Further Validation**: Consider using additional validation techniques or datasets to confirm the model's performance.\n",
    "\n",
    "   - **Model Tuning**: Explore further hyperparameter tuning or model adjustments to improve generalization.\n",
    "   \n",
    "Overall, while the new split accuracy is higher, the cross-validation results provide a more reliable indication of how the model might perform in real-world scenarios. It's important to ensure that the model is not overly tailored to a specific subset of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further validation examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Use a Validation Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV Score: 0.796\n"
     ]
    }
   ],
   "source": [
    "### 2. Nested Cross-Validation\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {'C': [0.1, 1, 10], 'max_iter': [100, 200]}\n",
    "\n",
    "# Outer cross-validation loop\n",
    "outer_cv_scores = cross_val_score(GridSearchCV(LogisticRegression(), param_grid, cv=5), X, y, cv=5)\n",
    "print(\"Nested CV Score:\", outer_cv_scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-Fold Mean Accuracy: 0.7960 ± 0.0049\n",
      "Stratified K-Fold Mean Precision: 0.7960 ± 0.0049\n",
      "Stratified K-Fold Mean Recall: 1.0000 ± 0.0000\n",
      "Stratified K-Fold Mean F1 Score: 0.8864 ± 0.0030\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### 3. Stratified K-Fold Cross-Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a list to store evaluation metrics\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Perform Stratified K-Fold Cross-Validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    precision_list.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recall_list.append(recall_score(y_test, y_pred, zero_division=0))\n",
    "    f1_list.append(f1_score(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Calculate the mean and standard deviation of the evaluation metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "std_precision = np.std(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "std_recall = np.std(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Stratified K-Fold Mean Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Stratified K-Fold Mean Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Stratified K-Fold Mean Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Stratified K-Fold Mean F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6. External Validation\n",
    "# Assuming you have an external dataset\n",
    "#X_external, y_external = load_external_data()\n",
    "# Evaluate your model on this external dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Mean Accuracy: 0.8110 ± 0.0333\n",
      "Bootstrap Mean Precision: 0.8089 ± 0.0329\n",
      "Bootstrap Mean Recall: 0.9997 ± 0.0019\n",
      "Bootstrap Mean F1 Score: 0.8939 ± 0.0204\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### 7. Bootstrapping\n",
    "\n",
    "\n",
    "### Bootstrapping with Model Training and Evaluation\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a list to store evaluation metrics\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# Number of bootstrap iterations\n",
    "n_iterations = 100\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(n_iterations):\n",
    "    # Resample the data\n",
    "    X_resampled, y_resampled = resample(X, y, random_state=i)\n",
    "    \n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(\n",
    "        X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_resampled = model.predict(X_test_resampled)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy_list.append(accuracy_score(y_test_resampled, y_pred_resampled))\n",
    "    precision_list.append(precision_score(y_test_resampled, y_pred_resampled, zero_division=0))\n",
    "    recall_list.append(recall_score(y_test_resampled, y_pred_resampled, zero_division=0))\n",
    "    f1_list.append(f1_score(y_test_resampled, y_pred_resampled, zero_division=0))\n",
    "\n",
    "# Calculate the mean and standard deviation of the evaluation metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "std_precision = np.std(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "std_recall = np.std(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Bootstrap Mean Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Bootstrap Mean Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Bootstrap Mean Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Bootstrap Mean F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>VotingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### 8. Ensemble Methods\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define multiple models\n",
    "model1 = LogisticRegression()\n",
    "model2 = RandomForestClassifier()\n",
    "model3 = SVC()\n",
    "\n",
    "# Create an ensemble of models\n",
    "ensemble = VotingClassifier(estimators=[('lr', model1), ('rf', model2), ('svc', model3)], voting='hard')\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Performance:\n",
      "Accuracy: 0.78\n",
      "Precision: 0.6224242424242424\n",
      "Recall: 0.78\n",
      "F1 Score: 0.6923595505617978\n",
      "Confusion Matrix:\n",
      "[[ 0 21]\n",
      " [ 1 78]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Example Code for Evaluation:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "y_pred_ensemble = ensemble.predict(X_test)\n",
    "ensemble_accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
    "ensemble_precision = precision_score(y_test, y_pred_ensemble, average='weighted')\n",
    "ensemble_recall = recall_score(y_test, y_pred_ensemble, average='weighted')\n",
    "ensemble_f1 = f1_score(y_test, y_pred_ensemble, average='weighted')\n",
    "\n",
    "print(\"Ensemble Model Performance:\")\n",
    "print(f\"Accuracy: {ensemble_accuracy}\")\n",
    "print(f\"Precision: {ensemble_precision}\")\n",
    "print(f\"Recall: {ensemble_recall}\")\n",
    "print(f\"F1 Score: {ensemble_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_ensemble))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### 9. Sensitivity Analysis\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Train your model\n",
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Perform sensitivity analysis\n",
    "result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "print(\"Feature importances:\", result.importances_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the different validation techniques (excluding external validation), we need to consider how each method evaluates the model's performance and what insights it provides. Here's a comparison of the techniques and an explanation of their results:\n",
    "\n",
    "### Validation Techniques Compared:\n",
    "\n",
    "1. **Validation Set Approach**:\n",
    "   - **Description**: Splits the data into training, validation, and test sets. The validation set is used for tuning and model selection, while the test set is reserved for final evaluation.\n",
    "   - **Pros**: Simple to implement and understand.\n",
    "   - **Cons**: The model's performance can be sensitive to how the data is split, and it may not use all available data for training.\n",
    "\n",
    "2. **Nested Cross-Validation**:\n",
    "   - **Description**: Involves an inner loop for hyperparameter tuning and an outer loop for model evaluation. Provides an unbiased estimate of model performance.\n",
    "   - **Pros**: Offers a robust evaluation by separating hyperparameter tuning from model evaluation.\n",
    "   - **Cons**: Computationally expensive due to multiple rounds of cross-validation.\n",
    "\n",
    "3. **Stratified K-Fold Cross-Validation**:\n",
    "   - **Description**: Divides the data into \\( k \\) folds, ensuring each fold has the same class distribution as the entire dataset.\n",
    "   - **Pros**: Reduces bias and variance in performance estimates, especially useful for imbalanced datasets.\n",
    "   - **Cons**: More computationally intensive than a simple train-test split.\n",
    "\n",
    "4. **Leave-One-Out Cross-Validation (LOOCV)**:\n",
    "   - **Description**: Uses each data point once as a test set while the rest are used for training.\n",
    "   - **Pros**: Uses the maximum amount of data for training, providing a thorough evaluation.\n",
    "   - **Cons**: Very computationally expensive, especially for large datasets.\n",
    "\n",
    "5. **Time Series Cross-Validation**:\n",
    "   - **Description**: Respects the temporal order of data, using past data to predict future data.\n",
    "   - **Pros**: Suitable for time-dependent data, maintaining the sequence of events.\n",
    "   - **Cons**: Not applicable to non-time series data.\n",
    "\n",
    "6. **Bootstrapping**:\n",
    "   - **Description**: Resamples the dataset with replacement to create multiple training sets.\n",
    "   - **Pros**: Provides estimates of model performance variability and robustness.\n",
    "   - **Cons**: Can be computationally intensive and may not always reflect the original data distribution.\n",
    "\n",
    "### Comparison and Explanation:\n",
    "\n",
    "- **Robustness and Generalization**: Nested cross-validation and stratified k-fold cross-validation provide robust estimates of model performance by using multiple data splits. They are particularly useful for ensuring that the model generalizes well to unseen data.\n",
    "\n",
    "- **Computational Cost**: LOOCV and nested cross-validation are the most computationally expensive methods. They are thorough but may not be practical for very large datasets.\n",
    "\n",
    "- **Handling Imbalanced Data**: Stratified k-fold cross-validation is particularly effective for imbalanced datasets, ensuring that each fold is representative of the overall class distribution.\n",
    "\n",
    "- **Time-Dependent Data**: Time series cross-validation is essential for datasets where the temporal order matters, such as stock prices or weather data.\n",
    "\n",
    "- **Variability and Stability**: Bootstrapping provides insights into the variability and stability of model performance across different samples, which can be valuable for understanding model reliability.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Each validation technique has its strengths and weaknesses, and the choice of method should be guided by the specific characteristics of the dataset and the goals of the analysis. For general purposes, stratified k-fold cross-validation is often a good balance between robustness and computational efficiency. However, for time series data, time series cross-validation is more appropriate, and for hyperparameter tuning, nested cross-validation provides a more unbiased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results:\n",
      "  Accuracy: 0.8600\n",
      "  Precision: 0.8600\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.9247\n",
      "\n",
      "Nested CV Results:\n",
      "  Mean Accuracy: 0.7960\n",
      "  Std Dev: 0.0049\n",
      "\n",
      "Stratified K-Fold Results:\n",
      "  Mean Accuracy: 0.7960\n",
      "  Std Dev: 0.0049\n",
      "\n",
      "LOOCV Results:\n",
      "  Mean Accuracy: 0.7960\n",
      "  Std Dev: 0.4030\n",
      "\n",
      "Time Series CV Results:\n",
      "  Mean Accuracy: 0.7880\n",
      "  Std Dev: 0.0467\n",
      "\n",
      "Bootstrapping Results:\n",
      "  Mean Accuracy: 0.8110\n",
      "  Std Dev: 0.0333\n",
      "\n",
      "Interpretation:\n",
      "The results show the mean accuracy and standard deviation for each validation technique.\n",
      "Higher mean accuracy and lower standard deviation indicate better and more stable model performance.\n",
      "Nested CV and Stratified K-Fold are generally more robust, while LOOCV provides a thorough evaluation but is computationally expensive.\n",
      "Bootstrapping provides insights into model variability, and Time Series CV is essential for time-dependent data.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, LeaveOneOut, TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Assuming X and y are your features and labels\n",
    "# X, y = load_your_data()\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# 1. Validation Set Approach\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "results['Validation Set'] = {\n",
    "    'Accuracy': accuracy_score(y_val, y_pred),\n",
    "    'Precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "    'Recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "    'F1 Score': f1_score(y_val, y_pred, zero_division=0)\n",
    "}\n",
    "\n",
    "# 2. Nested Cross-Validation\n",
    "param_grid = {'C': [0.1, 1, 10], 'max_iter': [100, 200]}\n",
    "nested_cv = cross_val_score(GridSearchCV(LogisticRegression(), param_grid, cv=5), X, y, cv=5)\n",
    "results['Nested CV'] = {\n",
    "    'Mean Accuracy': nested_cv.mean(),\n",
    "    'Std Dev': nested_cv.std()\n",
    "}\n",
    "\n",
    "# 3. Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf_scores = cross_val_score(LogisticRegression(random_state=42), X, y, cv=skf)\n",
    "results['Stratified K-Fold'] = {\n",
    "    'Mean Accuracy': skf_scores.mean(),\n",
    "    'Std Dev': skf_scores.std()\n",
    "}\n",
    "\n",
    "# 4. Leave-One-Out Cross-Validation (LOOCV)\n",
    "loo = LeaveOneOut()\n",
    "loo_scores = cross_val_score(LogisticRegression(random_state=42), X, y, cv=loo)\n",
    "results['LOOCV'] = {\n",
    "    'Mean Accuracy': loo_scores.mean(),\n",
    "    'Std Dev': loo_scores.std()\n",
    "}\n",
    "\n",
    "# 5. Time Series Cross-Validation\n",
    "# Assuming X is sorted by time\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "tscv_scores = cross_val_score(LogisticRegression(random_state=42), X, y, cv=tscv)\n",
    "results['Time Series CV'] = {\n",
    "    'Mean Accuracy': tscv_scores.mean(),\n",
    "    'Std Dev': tscv_scores.std()\n",
    "}\n",
    "\n",
    "# 6. Bootstrapping\n",
    "n_iterations = 100\n",
    "bootstrap_accuracies = []\n",
    "for i in range(n_iterations):\n",
    "    X_resampled, y_resampled = resample(X, y, random_state=i)\n",
    "    X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(\n",
    "        X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred_resampled = model.predict(X_test_resampled)\n",
    "    bootstrap_accuracies.append(accuracy_score(y_test_resampled, y_pred_resampled))\n",
    "results['Bootstrapping'] = {\n",
    "    'Mean Accuracy': np.mean(bootstrap_accuracies),\n",
    "    'Std Dev': np.std(bootstrap_accuracies)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "for method, metrics in results.items():\n",
    "    print(f\"{method} Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Interpretation\n",
    "print(\"Interpretation:\")\n",
    "print(\"The results show the mean accuracy and standard deviation for each validation technique.\")\n",
    "print(\"Higher mean accuracy and lower standard deviation indicate better and more stable model performance.\")\n",
    "print(\"Nested CV and Stratified K-Fold are generally more robust, while LOOCV provides a thorough evaluation but is computationally expensive.\")\n",
    "print(\"Bootstrapping provides insights into model variability, and Time Series CV is essential for time-dependent data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|      | Accuracy | Precision | Recall | F1 Score | Mean Accuracy | Std Dev |\n",
    "|--------------------------|----------|-----------|--------|----------|---------------|---------|\n",
    "| Validation Set           | 0.8600   | 0.8600    | 1.0000 | 0.9247   | N/A           | N/A     |\n",
    "\n",
    "### Result comparison\n",
    "\n",
    "| Validation Technique     | Mean Accuracy | Std Dev |\n",
    "|--------------------------|---------------|---------|\n",
    "| Nested CV                |  0.7960        | 0.0049  |\n",
    "| Stratified K-Fold        |  0.7960        | 0.0049  |\n",
    "| LOOCV                    |  0.7960        | 0.4030  |\n",
    "| Time Series CV           |  0.7880        | 0.0467  |\n",
    "| Bootstrapping            |  0.8110        | 0.0333  |\n",
    "\n",
    "### Explanation:\n",
    "- **Validation Set**: Provides specific metrics like accuracy, precision, recall, and F1 score.\n",
    "- **Nested CV, Stratified K-Fold, LOOCV, Time Series CV, Bootstrapping**: These techniques provide mean accuracy and standard deviation, which are useful for understanding the model's performance stability across different data splits or resamples.\n",
    "\n",
    "This table allows for a quick comparison of the different validation techniques and their results.\n",
    "\n",
    "### Conclusion\n",
    "The results show the mean accuracy and standard deviation for each validation technique.\n",
    "\n",
    "Higher mean accuracy and lower standard deviation indicate better and more stable model performance.\n",
    "\n",
    "Nested CV and Stratified K-Fold have the lowest standard deviations, indicating that these methods provide the most consistent performance across different data splits - therefore are generally more robust, while LOOCV, having a much higher standard deviation, it can have signifficant variability in performance despite providing a thorough evaluation which is computationally expensive - but this might be doe to the size of the test set in each interaction.\n",
    "\n",
    "\n",
    "- **Best Overall Performance**: **Bootstrapping** shows the highest mean accuracy, suggesting it might be the best choice if the goal is to maximize accuracy.\n",
    "\n",
    "- **Consistency**: **Nested CV** and **Stratified K-Fold** offer the most consistent results, which is crucial for ensuring that the model's performance is reliable across different data samples.\n",
    "\n",
    "\n",
    "- **Considerations**: The choice of the best technique also depends on the specific context and requirements. For example, if computational resources are limited, the computational cost of LOOCV might be prohibitive despite its thoroughness.\n",
    "\n",
    "\n",
    "In summary, if you prioritize accuracy, Bootstrapping might be the best choice. However, if you value consistency and robustness, Nested CV or Stratified K-Fold would be preferable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stress testing LOOCV to see if we can improve STDEV\n",
    "\n",
    "To evaluate the Leave-One-Out Cross-Validation (LOOCV) with different train-test split options, we can simulate this by using different random seeds for splitting the data. However, LOOCV inherently uses each data point as a test set once, so it doesn't involve random splits like other methods. Instead, we can compare LOOCV with other small-sample cross-validation techniques to see which provides the lowest standard deviation.\n",
    "\n",
    "Since LOOCV is inherently deterministic, I'll demonstrate how to use different small-sample cross-validation techniques and compare their standard deviations\n",
    "\n",
    "- **LOOCV**: Uses each data point as a test set once, providing a thorough evaluation but can be computationally expensive.\n",
    "\n",
    "- **K-Fold (k=5)**: Splits the data into 5 folds, providing a balance between thoroughness and computational efficiency.\n",
    "\n",
    "- **ShuffleSplit**: Randomly splits the data into training and test sets multiple times, providing a robust estimate of model performance.\n",
    "\n",
    "- **Stratified K-Fold**: Ensures each fold has a representative distribution of the target classes, useful for imbalanced datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV Results:\n",
      "  Mean Accuracy: 0.9533\n",
      "  Std Dev: 0.2109\n",
      "\n",
      "K-Fold (k=5) Results:\n",
      "  Mean Accuracy: 0.9600\n",
      "  Std Dev: 0.0249\n",
      "\n",
      "ShuffleSplit Results:\n",
      "  Mean Accuracy: 0.9600\n",
      "  Std Dev: 0.0249\n",
      "\n",
      "Stratified K-Fold Results:\n",
      "  Mean Accuracy: 0.9533\n",
      "  Std Dev: 0.0452\n",
      "\n",
      "Interpretation:\n",
      "The results show the mean accuracy and standard deviation for each cross-validation technique.\n",
      "Lower standard deviation indicates more consistent performance across different splits.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, ShuffleSplit, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load a sample dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# 1. Leave-One-Out Cross-Validation (LOOCV)\n",
    "loo = LeaveOneOut()\n",
    "loo_scores = cross_val_score(LogisticRegression(max_iter=1000, random_state=42), X_scaled, y, cv=loo)\n",
    "results['LOOCV'] = {\n",
    "    'Mean Accuracy': loo_scores.mean(),\n",
    "    'Std Dev': loo_scores.std()\n",
    "}\n",
    "\n",
    "# 2. K-Fold Cross-Validation with small k\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "kf_scores = cross_val_score(LogisticRegression(max_iter=1000, random_state=42), X_scaled, y, cv=kf)\n",
    "results['K-Fold (k=5)'] = {\n",
    "    'Mean Accuracy': kf_scores.mean(),\n",
    "    'Std Dev': kf_scores.std()\n",
    "}\n",
    "\n",
    "# 3. ShuffleSplit Cross-Validation\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "ss_scores = cross_val_score(LogisticRegression(max_iter=1000, random_state=42), X_scaled, y, cv=ss)\n",
    "results['ShuffleSplit'] = {\n",
    "    'Mean Accuracy': ss_scores.mean(),\n",
    "    'Std Dev': ss_scores.std()\n",
    "}\n",
    "\n",
    "# 4. Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "skf_scores = cross_val_score(LogisticRegression(max_iter=1000, random_state=42), X_scaled, y, cv=skf)\n",
    "results['Stratified K-Fold'] = {\n",
    "    'Mean Accuracy': skf_scores.mean(),\n",
    "    'Std Dev': skf_scores.std()\n",
    "}\n",
    "\n",
    "# Print results\n",
    "for method, metrics in results.items():\n",
    "    print(f\"{method} Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Interpretation\n",
    "print(\"Interpretation:\")\n",
    "print(\"The results show the mean accuracy and standard deviation for each cross-validation technique.\")\n",
    "print(\"Lower standard deviation indicates more consistent performance across different splits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
